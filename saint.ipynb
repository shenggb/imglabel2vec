{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import zipfile\n",
    "# root_path = 'mini-imagenet'\n",
    "# zip_ref = zipfile.ZipFile(os.path.join(root_path,'mini-imagenet.zip'), 'r')\n",
    "# zip_ref.extractall(root_path)\n",
    "# zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import collections\n",
    "from PIL import Image\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniImagenet(Dataset):\n",
    "    \"\"\"\n",
    "    put mini-imagenet files as :\n",
    "    root :\n",
    "        |- images/*.jpg includes all images\n",
    "        |- train.csv  len(labels):64\n",
    "        |- test.csv   len(labels):20\n",
    "        |- val.csv    len(labels):16\n",
    "    NOTICE: meta-learning is different from general supervised learning, especially the concept of batch and set.\n",
    "    batch: contains several sets\n",
    "    sets: conains n_way * k_shot for meta-train set, n_way * n_query for meta-test set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, mode, batchsz, n_way, k_shot, k_query, resize, startidx=0):\n",
    "        \"\"\"\n",
    "        :param startidx: start to index label from startidx\n",
    "        \"\"\"\n",
    "        \n",
    "        self.batchsz = batchsz  # batch of set, not batch of imgs\n",
    "        self.n_way = n_way  # n-way\n",
    "        self.k_shot = k_shot  # k-shot\n",
    "        self.k_query = k_query  # for evaluation\n",
    "        self.setsz = self.n_way * self.k_shot  # num of samples per support set\n",
    "        self.querysz = self.k_query  # number of samples per set for evaluation\n",
    "        self.resize = resize  # resize to\n",
    "        self.startidx = startidx  # index label not from 0, but from startidx\n",
    "        print('shuffle DB :%s, b:%d, %d-way, %d-shot, %d-query, resize:%d' % (mode, batchsz, n_way, k_shot, k_query, resize))\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.transform = transforms.Compose([lambda x: Image.open(x).convert('RGB'),\n",
    "                                                 transforms.Resize((self.resize, self.resize)),\n",
    "                                                 # transforms.RandomHorizontalFlip(),\n",
    "                                                 # transforms.RandomRotation(5),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                                 ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([lambda x: Image.open(x).convert('RGB'),\n",
    "                                                 transforms.Resize((self.resize, self.resize)),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                                 ])\n",
    "\n",
    "        self.path = os.path.join(root, 'images')  # image path\n",
    "        \n",
    "        # :return: dictLabels: {label1: [filename1, filename2, filename3, filename4,...], }\n",
    "        dictLabels = self.loadCSV(os.path.join(root, mode + '.csv'))  # csv path\n",
    "        self.data = []\n",
    "        self.img2label = {}\n",
    "        for i, (label, imgs) in enumerate(dictLabels.items()):\n",
    "            self.data.append(imgs)  # [[img1, img2, ...], [img111, ...]]\n",
    "            self.img2label[label] = i + self.startidx  # {\"img_name[:9]\":label}   {'n0134':0,'n0123':1,'n0123':2}\n",
    "        self.cls_num = len(self.data)\n",
    "\n",
    "        self.create_batch(self.batchsz)\n",
    "\n",
    "    def loadCSV(self, csvf):\n",
    "        \"\"\"\n",
    "        return a dict saving the information of csv\n",
    "        :param splitFile: csv file name\n",
    "        :return: {label:[file1, file2 ...]}\n",
    "        \"\"\"\n",
    "        dictLabels = {}\n",
    "        with open(csvf) as csvfile:\n",
    "            csvreader = csv.reader(csvfile, delimiter=',')\n",
    "            next(csvreader, None)  # skip (filename, label)\n",
    "            for i, row in enumerate(csvreader):\n",
    "                filename = row[0]\n",
    "                label = row[1]\n",
    "                # append filename to current label\n",
    "                if label in dictLabels.keys():\n",
    "                    dictLabels[label].append(filename)\n",
    "                else:\n",
    "                    dictLabels[label] = [filename]\n",
    "        return dictLabels\n",
    "\n",
    "    def create_batch(self, batchsz):\n",
    "        \"\"\"\n",
    "        create batch for meta-learning.\n",
    "        ×episode× here means batch, and it means how many sets we want to retain.\n",
    "        :param episodes: batch size\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.support_x_batch = []  # support set batch\n",
    "        self.query_x_batch = []  # query set batch\n",
    "        for b in range(batchsz):  # for each batch\n",
    "            # 1.select n_way classes randomly\n",
    "            selected_cls = np.random.choice(self.cls_num, self.n_way, False)  #False: no duplicate不重复\n",
    "            np.random.shuffle(selected_cls)\n",
    "            support_x = []\n",
    "            query_x = []\n",
    "            for cls in selected_cls:\n",
    "                \n",
    "                # 2. select k_shot + k_query for each class\n",
    "                selected_imgs_idx = np.random.choice(len(self.data[cls]), self.k_shot + self.k_query, False)\n",
    "                np.random.shuffle(selected_imgs_idx)\n",
    "                indexDtrain = np.array(selected_imgs_idx[:self.k_shot])  # idx for Dtrain\n",
    "                indexDtest = np.array(selected_imgs_idx[self.k_shot:])  # idx for Dtest\n",
    "                support_x.append(\n",
    "                    np.array(self.data[cls])[indexDtrain].tolist())        # get all images filename for current Dtrain\n",
    "            query_x.append(np.array(self.data[cls])[indexDtest].tolist())\n",
    "\n",
    "            # shuffle the correponding relation between support set and query set\n",
    "            random.shuffle(support_x)\n",
    "            random.shuffle(query_x)\n",
    "\n",
    "            self.support_x_batch.append(support_x)  # append set to current sets\n",
    "            self.query_x_batch.append(query_x)  # append sets to current sets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        index means index of sets, 0<= index <= batchsz-1\n",
    "        :param index:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        support_x = torch.FloatTensor(self.setsz, 3, self.resize, self.resize)\n",
    "        support_y = np.zeros((self.setsz), dtype=np.int32)\n",
    "        \n",
    "        query_x = torch.FloatTensor(self.querysz, 3, self.resize, self.resize)\n",
    "        query_y = np.zeros((self.querysz), dtype=np.int32)\n",
    "        \n",
    "        flatten_support_x = [os.path.join(self.path, item)\n",
    "                             for sublist in self.support_x_batch[index] for item in sublist]\n",
    "        support_y = np.array(\n",
    "            [self.img2label[item[:9]]  # filename:n0153282900000005.jpg, the first 9 characters treated as label\n",
    "             for sublist in self.support_x_batch[index] for item in sublist]).astype(np.int32)\n",
    "        \n",
    "\n",
    "        flatten_query_x = [os.path.join(self.path, item)\n",
    "                           for sublist in self.query_x_batch[index] for item in sublist]\n",
    "        query_y = np.array([self.img2label[item[:9]]\n",
    "                            for sublist in self.query_x_batch[index] for item in sublist]).astype(np.int32)\n",
    "        \n",
    "        # print('global:', support_y, query_y)\n",
    "        # support_y: [setsz]\n",
    "        # query_y: [querysz]\n",
    "        # unique: [n-way], sorted\n",
    "#         unique = np.unique(support_y)\n",
    "#         random.shuffle(unique)\n",
    "        # relative means the label ranges from 0 to n-way\n",
    "#         support_y_relative = np.zeros(self.setsz)\n",
    "#         query_y_relative = np.zeros(self.querysz)\n",
    "\n",
    "#         for idx, l in enumerate(unique):\n",
    "#             support_y_relative[support_y == l] = idx\n",
    "#             query_y_relative[query_y == l] = idx\n",
    "\n",
    "        # print('relative:', support_y_relative, query_y_relative)\n",
    "\n",
    "        for i, path in enumerate(flatten_support_x):\n",
    "            support_x[i] = self.transform(path)\n",
    "\n",
    "        for i, path in enumerate(flatten_query_x):\n",
    "            query_x[i] = self.transform(path)\n",
    "        # print(support_set_y)\n",
    "        # return support_x, torch.LongTensor(support_y), query_x, torch.LongTensor(query_y)\n",
    "\n",
    "        return support_x, torch.LongTensor(support_y), query_x, torch.LongTensor(query_y)\n",
    "\n",
    "    def __len__(self):\n",
    "        # as we have built up to batchsz of sets, you can sample some small batch size of sets.\n",
    "        return self.batchsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),     #84 -> 42\n",
    "            \n",
    "            nn.Conv2d(32,32,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),    #42 -> 21\n",
    "            \n",
    "            nn.Conv2d(32,32,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),   #21 -> 10\n",
    "            \n",
    "            nn.Conv2d(32,32,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),  #10 -> 5\n",
    "        )\n",
    "        self.fc = nn.Linear(32 * 5 * 5, 500)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.reshape(-1,32*5*5)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Tripletnet(nn.Module):\n",
    "    def __init__(self, embeddingnet):\n",
    "        super(Tripletnet, self).__init__()\n",
    "        self.embeddingnet = embeddingnet\n",
    "        self.anchor_embedding = nn.Embedding(100,500)  #100个类别，每个类别500维\n",
    "        \n",
    "    def forward(self, x_support,y_support):  #[2,3,84,84],[2]\n",
    "        p = x_support[0].unsqueeze(0)\n",
    "        n = x_support[1].unsqueeze(0)\n",
    "        \n",
    "        embedded_a = self.anchor_embedding(y_support[0])  #support_x中第一张图片为正样本，第二张为负样本\n",
    "        embedded_a = embedded_a.unsqueeze(0)\n",
    "        embedded_p = self.embeddingnet(p)\n",
    "        embedded_n = self.embeddingnet(n)\n",
    "        return embedded_a, embedded_p, embedded_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = Net().to(device)\n",
    "tnet = Tripletnet(model).to(device)\n",
    "\n",
    "loss_fn = torch.nn.TripletMarginLoss(margin = 100)\n",
    "loss_ce = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(tnet.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle DB :train, b:1000, 2-way, 1-shot, 1-query, resize:84\n",
      "shuffle DB :test, b:1000, 2-way, 1-shot, 1-query, resize:84\n",
      "shuffle DB :val, b:1000, 2-way, 1-shot, 1-query, resize:84\n",
      "train_acc: 0.001\n",
      "val_acc: 0.001\n",
      "val_acc: 0.002\n",
      "val_acc: 0.003\n",
      "val_acc: 0.004\n",
      "val_acc: 0.005\n",
      "val_acc: 0.005\n",
      "val_acc: 0.006\n",
      "val_acc: 0.007\n",
      "val_acc: 0.008\n",
      "val_acc: 0.008\n",
      "val_acc: 0.009\n",
      "val_acc: 0.01\n",
      "val_acc: 0.012\n",
      "val_acc: 0.012\n",
      "val_acc: 0.012\n",
      "val_acc: 0.013\n",
      "val_acc: 0.014\n",
      "val_acc: 0.014\n",
      "val_acc: 0.015\n",
      "val_acc: 0.016\n",
      "val_acc: 0.016\n",
      "val_acc: 0.016\n",
      "val_acc: 0.017\n"
     ]
    }
   ],
   "source": [
    "mini_train = MiniImagenet('mini-imagenet/', mode='train', n_way=2, k_shot=1,\n",
    "                        k_query=1,batchsz=1000, resize=84, startidx=0)\n",
    "mini_test = MiniImagenet('mini-imagenet/', mode='test', n_way=2, k_shot=1,\n",
    "                         k_query=1,batchsz=1000, resize=84, startidx=64)\n",
    "mini_val = MiniImagenet('mini-imagenet/', mode='val', n_way=2, k_shot=1,\n",
    "                         k_query=1,batchsz=1000, resize=84, startidx=84)\n",
    "\n",
    "\n",
    "for epoch in range(30):\n",
    "    db = torch.utils.data.DataLoader(mini_train, 4, shuffle=True, num_workers=0, pin_memory=True) \n",
    "    correct_num = 0\n",
    "    \n",
    "    for k,(support_x,support_y,query_x,query_y) in enumerate(db):\n",
    "        support_x,support_y,query_x,query_y = support_x.to(device),support_y.to(device),query_x.to(device),query_y.to(device)\n",
    "        pred_cos = list()\n",
    "        q_y = list()\n",
    "        pred = list()\n",
    "        for i in support_y.eq(query_y).int():\n",
    "            idx= torch.argmax(i)\n",
    "            q_y.append(idx.item())\n",
    "            \n",
    "        for i in range(4):\n",
    "            \n",
    "            for step in range(4):\n",
    "                embedded_a, embedded_p, embedded_n = tnet(support_x[i],support_y[i])\n",
    "                loss = loss_fn(embedded_a, embedded_p, embedded_n)  #loss = criterion(anchor, positive, negative)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            embedded_query = model(query_x[i])\n",
    "            q_p_cos = F.cosine_similarity(embedded_query,embedded_p)\n",
    "            q_n_cos = F.cosine_similarity(embedded_query,embedded_n)\n",
    "            pred_cos.append([q_p_cos.item(),q_n_cos.item()])\n",
    "            \n",
    "\n",
    "        if q_p_cos > q_n_cos:\n",
    "            pred.append(support_y[i][0].item())\n",
    "        else:\n",
    "            pred.append(support_y[i][1].item())\n",
    "\n",
    "        for step in range(4):\n",
    "            pred_cos_tensor = torch.tensor(pred_cos, requires_grad=True)\n",
    "            loss_query = loss_ce(pred_cos_tensor,torch.tensor(q_y))\n",
    "            optimizer.zero_grad()\n",
    "            loss_query.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        correct_num += torch.tensor(pred).eq(query_y.squeeze().cpu()).sum().item()\n",
    "        if k % 100 == 0:\n",
    "            print('train_acc:',correct_num/1000)\n",
    "    \n",
    "#----------------------------------------------val验证--------------------------------------------------------------------\n",
    "    \n",
    "        db_val = torch.utils.data.DataLoader(mini_val, 4, shuffle=True, num_workers=0, pin_memory=True) \n",
    "        val_correct_num = 0\n",
    "\n",
    "        for support_x,support_y,query_x,query_y in db_val:\n",
    "            support_x,support_y,query_x,query_y = support_x.to(device),support_y.to(device),query_x.to(device),query_y.to(device)\n",
    "            pred_cos = list()\n",
    "            q_y = list()\n",
    "            pred = list()\n",
    "            for i in support_y.eq(query_y).int():\n",
    "                idx= torch.argmax(i)\n",
    "                q_y.append(idx.item())\n",
    "\n",
    "            for i in range(4):\n",
    "\n",
    "                for step in range(4):\n",
    "                    embedded_a, embedded_p, embedded_n = tnet(support_x[i],support_y[i])\n",
    "                    loss = loss_fn(embedded_a, embedded_p, embedded_n)  #loss = criterion(anchor, positive, negative)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                embedded_query = model(query_x[i])\n",
    "                q_p_cos = F.cosine_similarity(embedded_query,embedded_p)\n",
    "                q_n_cos = F.cosine_similarity(embedded_query,embedded_n)\n",
    "                pred_cos.append([q_p_cos.item(),q_n_cos.item()])\n",
    "\n",
    "                if q_p_cos > q_n_cos:\n",
    "                    pred.append(support_y[i][0].item())\n",
    "                else:\n",
    "                    pred.append(support_y[i][1].item())\n",
    "\n",
    "            for step in range(4):\n",
    "                pred_cos_tensor = torch.tensor(pred_cos, requires_grad=True)\n",
    "                loss_query = loss_ce(pred_cos_tensor,torch.tensor(q_y))\n",
    "                optimizer.zero_grad()\n",
    "                loss_query.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            val_correct_num += torch.tensor(pred).eq(query_y.squeeze().cpu()).sum().item()\n",
    "        print('val_acc:',correct_num/1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from torch import nn\n",
    "\n",
    "class Meta(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Meta, self).__init__()   \n",
    "        self.update_lr = 0.1 ## learner中的学习率，即\\alpha\n",
    "        self.meta_lr = 1e-3 ## meta-learner的学习率，即\\beta\n",
    "        self.n_way = 2 ## 5种类型\n",
    "        self.k_shot = 1 ## 一个样本\n",
    "        self.k_query = 1 ## 15个查询样本\n",
    "        self.update_step = 5   ## task-level inner update steps\n",
    "        self.update_step_test = 5 ## 用在finetunning这个函数中\n",
    "        \n",
    "        self.net = Learner(config)     ## base-learner\n",
    "        self.meta_optim = torch.optim.Adam(self.net.parameters(), lr = self.meta_lr)\n",
    "        \n",
    "    def forward(self, x_support, y_support, x_query, y_query):  # [2,5,3,84,84]\n",
    "        task_num, n, c, h, w = x_support.size()   # [2,5,3,84,84]\n",
    "        querysz = x_query.size(1)      ## 1\n",
    "        losses_q = [0 for _ in range(self.update_step +1)] ## losses_q[i] is the loss on step i\n",
    "        corrects = [0 for _ in range(self.update_step +1)]\n",
    "        \n",
    "            \n",
    "        pred_cos = list()\n",
    "        q_y = list()\n",
    "        pred = list()\n",
    "        for i in support_y.eq(query_y).int():\n",
    "            idx= torch.argmax(i)\n",
    "            q_y.append(idx.item())\n",
    "\n",
    "        for i in range(task_num):\n",
    "            for step in range(4):\n",
    "                embedded_a, embedded_p, embedded_n = tnet(support_x[i],support_y[i])\n",
    "                loss = loss_fn(embedded_a, embedded_p, embedded_n)  #loss = criterion(anchor, positive, negative)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            embedded_query = model(query_x[i])\n",
    "            q_p_cos = F.cosine_similarity(embedded_query,embedded_p)\n",
    "            q_n_cos = F.cosine_similarity(embedded_query,embedded_n)\n",
    "            pred_cos.append([q_p_cos.item(),q_n_cos.item()])\n",
    "\n",
    "            if q_p_cos > q_n_cos:\n",
    "                pred.append(support_y[i][0].item())\n",
    "            else:\n",
    "                pred.append(support_y[i][1].item())\n",
    "\n",
    "        for step in range(4):\n",
    "            pred_cos_tensor = torch.tensor(pred_cos, requires_grad=True)\n",
    "            loss_query = loss_ce(pred_cos_tensor,torch.tensor(q_y))\n",
    "            optimizer.zero_grad()\n",
    "            loss_query.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        correct_num += torch.tensor(pred).eq(query_y.squeeze().cpu()).sum().item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "            ## 第0步更新\n",
    "            logits = self.net(x_support[i], vars=None, bn_training = True)   ## return 一个经过各层计算后的y\n",
    "            ## logits : 5*5的tensor\n",
    "            loss = F.cross_entropy(logits, y_support[i])  ## 计算Loss值\n",
    "            grad = torch.autograd.grad(loss, self.net.parameters())      ##计算梯度。如果输入x，输出是y，则求y关于x的导数（梯度）\n",
    "            tuples = zip(grad, self.net.parameters() ) ##将梯度grad和参数\\theta一一对应起来\n",
    "            ## fast_weights这一步相当于求了一个\\theta - \\alpha*\\nabla(L)\n",
    "            fast_weights = list( map(lambda p: p[1] - self.update_lr * p[0], tuples) ) ##更新子任务的theta__\n",
    "\n",
    "            \n",
    "            \n",
    "            ### 在query集上进行测试，计算准确率\n",
    "            ## 这一步使用的是更新前的参数\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_query[i], self.net.parameters(), bn_training = True) ## logits_q :torch.Size([75, 5])\n",
    "                loss_q = F.cross_entropy(logits_q, y_query[i]) ## y_query : torch.Size([75])\n",
    "                losses_q[0] += loss_q ##将loss存在数组的第一个位置\n",
    "                pred_q = F.softmax(logits_q, dim = 1).argmax(dim=1) ## size = (75)\n",
    "                correct = torch.eq(pred_q, y_query[i]).sum().item()## item()取出tensor中的数字\n",
    "                corrects[0] += correct\n",
    "            \n",
    "            ### 在query集上进行测试，计算准确率\n",
    "            ## 这一步使用的是更新后的参数\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_query[i], fast_weights, bn_training = True)   #fast_weights\n",
    "                loss_q = F.cross_entropy(logits_q, y_query[i])\n",
    "                losses_q[1] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim = 1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_query[i]).sum().item()\n",
    "                corrects[1] += correct\n",
    "             \n",
    "            \n",
    "            for k in range(1, self.update_step):   #k: [1,2,3,4]\n",
    "                logits = self.net(x_support[i], fast_weights, bn_training =True)\n",
    "                loss = F.cross_entropy(logits, y_support[i])\n",
    "                grad = torch.autograd.grad(loss, fast_weights)\n",
    "                tuples = zip(grad,fast_weights)\n",
    "                fast_weights = list(map(lambda p:p[1] - self.update_lr * p[0], tuples))  #更新参数\n",
    "                \n",
    "                if k < self.update_step - 1:  #k:[1,2,3]\n",
    "                    with torch.no_grad():   \n",
    "                        logits_q = self.net(x_query[i], fast_weights, bn_training = True)\n",
    "                        loss_q = F.cross_entropy(logits_q, y_query[i])\n",
    "                        losses_q[k+1] += loss_q\n",
    "                        \n",
    "                else:   #k: [4]\n",
    "                    logits_q = self.net(x_query[i], fast_weights, bn_training = True)\n",
    "                    loss_q = F.cross_entropy(logits_q, y_query[i])\n",
    "                    losses_q[k+1] += loss_q\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim = 1)\n",
    "                    correct = torch.eq(pred_q, y_query[i]).sum().item()\n",
    "                    corrects[k+1] += correct\n",
    "        \n",
    "        \n",
    "        ## 在一组task_num个任务结束后，求一个平均的loss,  残差可以吗？？？\n",
    "        loss_q = losses_q[-1] / task_num     \n",
    "        \n",
    "        self.meta_optim.zero_grad()   ## 梯度清零\n",
    "        loss_q.backward()        ## 计算梯度\n",
    "        #self.meta_optim = torch.optim.Adam(self.net.parameters(), lr = self.meta_lr)\n",
    "        self.meta_optim.step()   ## 用设置好的优化方法来迭代模型参数，这一步是meta步迭代, 更新多了 会不会过拟合???????????\n",
    "        \n",
    "        accs = np.array(corrects) / (querysz * task_num)   #corrects/75*task\n",
    "        \n",
    "        return accs\n",
    "        \n",
    "    \n",
    "    def finetunning(self, x_support, y_support, x_query, y_query):\n",
    "        assert len(x_support.shape) == 4\n",
    "        \n",
    "        querysz = x_query.size(0)\n",
    "        \n",
    "        corrects = [0 for _ in range(self.update_step_test + 1)]\n",
    "        \n",
    "        # in order to not ruin the state of running_mean/variance and bn_weight/bias\n",
    "        # we finetunning on the copied model instead of self.net\n",
    "        net = deepcopy(self.net)\n",
    "        \n",
    "        logits = net(x_support)\n",
    "        loss = F.cross_entropy(logits, y_support)\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters())))\n",
    "        \n",
    "        \n",
    "        ## 开始训练前的准确率\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_query, net.parameters(), bn_training = True)\n",
    "            pred_q = F.softmax(logits_q, dim =1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_query).sum().item()\n",
    "            corrects[0] += correct\n",
    "         \n",
    "        ## 训练后的准确率\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_query, fast_weights, bn_training = True)\n",
    "            pred_q = F.softmax(logits_q, dim = 1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_query).sum().item()\n",
    "            corrects[1] += correct\n",
    "            \n",
    "        for k in range(1, self.update_step_test):\n",
    "            logits = net(x_support, fast_weights, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_support)\n",
    "            grad = torch.autograd.grad(loss, fast_weights)\n",
    "            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0],   zip(grad, fast_weights)))\n",
    "            \n",
    "            logits_q = net(x_query, fast_weights, bn_training=True)\n",
    "            loss_q = F.cross_entropy(logits_q, y_query)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred_q = F.softmax(logits_q, dim =1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_query).sum().item()\n",
    "                corrects[k+1] += correct\n",
    "                \n",
    "        del net\n",
    "        \n",
    "        accs = np.array(corrects) / querysz\n",
    "        \n",
    "        return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
